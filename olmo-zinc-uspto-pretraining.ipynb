{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daab700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login('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') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a351af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile train_uspto.py\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    "    PeftModel\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import gc\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, LinearLR, SequentialLR\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# CONFIGURATION\n",
    "# ------------------------------------------------------------------------\n",
    "# HF_TOKEN = \"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\"\n",
    "\n",
    "MODEL_ID = \"Codemaster67/OLMo-7B-ZINC20-10k\" \n",
    "\n",
    "NEW_ADAPTER_NAME = \"Codemaster67/OLMo-7B-USPTO-1k-ZINC\"\n",
    "\n",
    "\n",
    "class OLMoQLoRA(pl.LightningModule):\n",
    "    def __init__(self, model_id, adapter_name):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model_id = model_id\n",
    "        self.adapter_name = adapter_name\n",
    "        \n",
    "        # OLMo requires trust_remote_code=True\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "    def configure_model(self):\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.float16,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "        )\n",
    "\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.model_id,\n",
    "            quantization_config=bnb_config,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "\n",
    "        model.config.use_cache = False\n",
    "        model.gradient_checkpointing_enable()\n",
    "        model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "        # QLoRA Config\n",
    "        peft_config = LoraConfig(\n",
    "            r=64,\n",
    "            lora_alpha=128,\n",
    "            target_modules=\"all-linear\",\n",
    "            lora_dropout=0.05,\n",
    "            bias=\"none\",\n",
    "            task_type=\"CAUSAL_LM\"\n",
    "        )\n",
    "        self.model = get_peft_model(model, peft_config)\n",
    "        \n",
    "        if self.trainer.is_global_zero:\n",
    "            self.model.print_trainable_parameters()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        return self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs = self(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            labels=batch[\"labels\"] \n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=True, sync_dist=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "        total_steps = self.trainer.estimated_stepping_batches\n",
    "\n",
    "        warmup_steps = int(0.15 * total_steps)\n",
    "        scheduler_warmup = LinearLR(\n",
    "            optimizer,\n",
    "            start_factor=0.001,\n",
    "            end_factor=1.0,\n",
    "            total_iters=warmup_steps,\n",
    "        )\n",
    "\n",
    "        scheduler_cosine = CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=total_steps - warmup_steps,\n",
    "        )\n",
    "\n",
    "        scheduler = SequentialLR(\n",
    "            optimizer,\n",
    "            schedulers=[scheduler_warmup, scheduler_cosine],\n",
    "            milestones=[warmup_steps]\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"step\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "class USPTODataModule(pl.LightningDataModule):\n",
    "    def __init__(self, tokenizer, batch_size=4):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.dataset = (\n",
    "            load_dataset(\"OpenMol/USPTO_1k_TPL-SFT\", split=\"train\", streaming=True, trust_remote_code=True)\n",
    "            .take(10_000)\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        def collate_fn(batch):\n",
    "            text_samples = []\n",
    "            for item in batch:\n",
    "\n",
    "                prompt = (\n",
    "                    f\"Instruction: {item['instruction']}\\n\"\n",
    "                    f\"Input: {item['input']}\\n\"\n",
    "                    f\"Output: {item['output']}\"\n",
    "                )\n",
    "                text_samples.append(prompt)\n",
    "            \n",
    "            encodings = self.tokenizer(\n",
    "                text_samples,\n",
    "                truncation=True,\n",
    "                max_length=512, \n",
    "                padding=\"max_length\",\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "            labels = encodings[\"input_ids\"].clone()\n",
    "            labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "            return {\n",
    "                \"input_ids\": encodings[\"input_ids\"],\n",
    "                \"attention_mask\": encodings[\"attention_mask\"],\n",
    "                \"labels\": labels\n",
    "            }\n",
    "\n",
    "        return DataLoader(\n",
    "            self.dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            collate_fn=collate_fn,\n",
    "        )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pl_model = OLMoQLoRA(MODEL_ID, NEW_ADAPTER_NAME)\n",
    "\n",
    "    dm = USPTODataModule(pl_model.tokenizer, batch_size=1)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=\"gpu\",\n",
    "        devices=2,                  \n",
    "        strategy=\"ddp\", \n",
    "        precision=\"16-mixed\",       \n",
    "        max_epochs=1,\n",
    "        accumulate_grad_batches=8,  \n",
    "        log_every_n_steps=10,\n",
    "        enable_checkpointing=False,\n",
    "        enable_progress_bar=False,\n",
    "        gradient_clip_val=0.5\n",
    "    )\n",
    "\n",
    "    print(f\"Starting Training on USPTO dataset (using base: {MODEL_ID})...\")\n",
    "    trainer.fit(pl_model, datamodule=dm)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # MERGE AND PUSH LOGIC\n",
    "    # ---------------------------------------------------------\n",
    "    if trainer.is_global_zero:\n",
    "        print(\"Training complete. Saving adapter to temporary local storage...\")\n",
    "        \n",
    "        pl_model.model.save_pretrained(\"./temp_adapter_uspto\")\n",
    "        pl_model.tokenizer.save_pretrained(\"./temp_adapter_uspto\")\n",
    "        \n",
    "        print(\"Freeing VRAM for merge process...\")\n",
    "        del pl_model\n",
    "        del trainer\n",
    "        del dm\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        print(\"Loading Base Model in FP16 for merging...\")\n",
    "        # NOTE: We load the ZINC-trained model as the base here\n",
    "        base_model = AutoModelForCausalLM.from_pretrained(\n",
    "            MODEL_ID,\n",
    "            return_dict=True,\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "\n",
    "        print(\"Loading Adapter and Merging...\")\n",
    "        model_to_merge = PeftModel.from_pretrained(base_model, \"./temp_adapter_uspto\")\n",
    "        model_to_merge = model_to_merge.merge_and_unload()\n",
    "        \n",
    "        print(f\"Pushing FULL MERGED model to Hub: {NEW_ADAPTER_NAME}\")\n",
    "        model_to_merge.push_to_hub(NEW_ADAPTER_NAME)\n",
    "        \n",
    "        # Push tokenizer as well\n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "        tokenizer.push_to_hub(NEW_ADAPTER_NAME)\n",
    "        \n",
    "        print(\"Done! Full merged USPTO model pushed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
