{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daab700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a351af30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train_uspto.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_uspto.py\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    "    PeftModel\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import gc\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, LinearLR, SequentialLR\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# CONFIGURATION\n",
    "# ------------------------------------------------------------------------\n",
    "# HF_TOKEN = \"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\"\n",
    "\n",
    "MODEL_ID = \"harindhar10/OLMo-7B-ZINC20-10k\" \n",
    "\n",
    "NEW_ADAPTER_NAME = \"harindhar10/OLMo-7B-USPTO-1k-ZINC\"\n",
    "\n",
    "\n",
    "class OLMoQLoRA(pl.LightningModule):\n",
    "    def __init__(self, model_id, adapter_name):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model_id = model_id\n",
    "        self.adapter_name = adapter_name\n",
    "        \n",
    "        # OLMo requires trust_remote_code=True\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "    def configure_model(self):\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.float16,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "        )\n",
    "\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.model_id,\n",
    "            quantization_config=bnb_config,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "\n",
    "        model.config.use_cache = False\n",
    "        model.gradient_checkpointing_enable()\n",
    "        model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "        # QLoRA Config\n",
    "        peft_config = LoraConfig(\n",
    "            r=64,\n",
    "            lora_alpha=128,\n",
    "            target_modules=\"all-linear\",\n",
    "            lora_dropout=0.05,\n",
    "            bias=\"none\",\n",
    "            task_type=\"CAUSAL_LM\"\n",
    "        )\n",
    "        self.model = get_peft_model(model, peft_config)\n",
    "        \n",
    "        if self.trainer.is_global_zero:\n",
    "            self.model.print_trainable_parameters()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        return self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs = self(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            labels=batch[\"labels\"] \n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=True, sync_dist=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "        total_steps = self.trainer.estimated_stepping_batches\n",
    "\n",
    "        warmup_steps = int(0.15 * total_steps)\n",
    "        scheduler_warmup = LinearLR(\n",
    "            optimizer,\n",
    "            start_factor=0.001,\n",
    "            end_factor=1.0,\n",
    "            total_iters=warmup_steps,\n",
    "        )\n",
    "\n",
    "        scheduler_cosine = CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=total_steps - warmup_steps,\n",
    "        )\n",
    "\n",
    "        scheduler = SequentialLR(\n",
    "            optimizer,\n",
    "            schedulers=[scheduler_warmup, scheduler_cosine],\n",
    "            milestones=[warmup_steps]\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"step\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "class USPTODataModule(pl.LightningDataModule):\n",
    "    def __init__(self, tokenizer, batch_size=8):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.dataset = (\n",
    "            load_dataset(\"OpenMol/USPTO_1k_TPL-SFT\", split=\"train\", streaming=True, trust_remote_code=True)\n",
    "            .take(10_000)\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        def collate_fn(batch):\n",
    "            text_samples = []\n",
    "            for item in batch:\n",
    "\n",
    "                prompt = (\n",
    "                    f\"Instruction: {item['instruction']}\\n\"\n",
    "                    f\"Input: {item['input']}\\n\"\n",
    "                    f\"Output: {item['output']}\"\n",
    "                )\n",
    "                text_samples.append(prompt)\n",
    "            \n",
    "            encodings = self.tokenizer(\n",
    "                text_samples,\n",
    "                truncation=True,\n",
    "                max_length=512, \n",
    "                padding=\"max_length\",\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "            labels = encodings[\"input_ids\"].clone()\n",
    "            labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "            return {\n",
    "                \"input_ids\": encodings[\"input_ids\"],\n",
    "                \"attention_mask\": encodings[\"attention_mask\"],\n",
    "                \"labels\": labels\n",
    "            }\n",
    "\n",
    "        return DataLoader(\n",
    "            self.dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            collate_fn=collate_fn,\n",
    "        )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pl_model = OLMoQLoRA(MODEL_ID, NEW_ADAPTER_NAME)\n",
    "\n",
    "    dm = USPTODataModule(pl_model.tokenizer, batch_size=2)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=\"gpu\",\n",
    "        devices=-1,                  \n",
    "        strategy=\"ddp\", \n",
    "        precision=\"16-mixed\",       \n",
    "        max_epochs=1,\n",
    "        accumulate_grad_batches=4,  \n",
    "        log_every_n_steps=10,\n",
    "        enable_checkpointing=False,\n",
    "        enable_progress_bar=True,\n",
    "        gradient_clip_val=0.5\n",
    "    )\n",
    "\n",
    "    print(f\"Starting Training on USPTO dataset (using base: {MODEL_ID})...\")\n",
    "    trainer.fit(pl_model, datamodule=dm)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # MERGE AND PUSH LOGIC\n",
    "    # ---------------------------------------------------------\n",
    "    if trainer.is_global_zero:\n",
    "        print(\"Training complete. Saving adapter to temporary local storage...\")\n",
    "        \n",
    "        pl_model.model.save_pretrained(\"./temp_adapter_uspto\")\n",
    "        pl_model.tokenizer.save_pretrained(\"./temp_adapter_uspto\")\n",
    "        \n",
    "        print(\"Freeing VRAM for merge process...\")\n",
    "        del pl_model\n",
    "        del trainer\n",
    "        del dm\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        print(\"Loading Base Model in FP16 for merging...\")\n",
    "        # NOTE: We load the ZINC-trained model as the base here\n",
    "        base_model = AutoModelForCausalLM.from_pretrained(\n",
    "            MODEL_ID,\n",
    "            return_dict=True,\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "\n",
    "        print(\"Loading Adapter and Merging...\")\n",
    "        model_to_merge = PeftModel.from_pretrained(base_model, \"./temp_adapter_uspto\")\n",
    "        model_to_merge = model_to_merge.merge_and_unload()\n",
    "        \n",
    "        print(f\"Pushing FULL MERGED model to Hub: {NEW_ADAPTER_NAME}\")\n",
    "        model_to_merge.push_to_hub(NEW_ADAPTER_NAME)\n",
    "        \n",
    "        # Push tokenizer as well\n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "        tokenizer.push_to_hub(NEW_ADAPTER_NAME)\n",
    "        \n",
    "        print(\"Done! Full merged USPTO model pushed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a61794f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/envs/pytorch/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Starting Training on USPTO dataset (using base: harindhar10/OLMo-7B-ZINC20-10k)...\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/envs/pytorch/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/envs/pytorch/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/envs/pytorch/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "Starting Training on USPTO dataset (using base: harindhar10/OLMo-7B-ZINC20-10k)...\n",
      "Starting Training on USPTO dataset (using base: harindhar10/OLMo-7B-ZINC20-10k)...\n",
      "Starting Training on USPTO dataset (using base: harindhar10/OLMo-7B-ZINC20-10k)...\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "[W Utils.hpp:133] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "[W Utils.hpp:133] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\n",
      "[W Utils.hpp:133] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\n",
      "[W Utils.hpp:133] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Fetching 3 files:   0%|                                   | 0/3 [00:00<?, ?it/s]\n",
      "Fetching 3 files:   0%|                                   | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "model-00003-of-00003.safetensors:   0%|             | 0.00/3.83G [00:00<?, ?B/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:   0%|             | 0.00/4.95G [00:00<?, ?B/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:   0%|    | 242k/5.00G [00:00<5:07:25, 271kB/s]\u001b[A\n",
      "model-00003-of-00003.safetensors:   0%| | 54.8k/3.83G [00:00<16:58:12, 62.7kB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:   1%|    | 66.8M/5.00G [00:00<00:53, 92.1MB/s]\u001b[A\n",
      "model-00003-of-00003.safetensors:   1%|    | 55.0M/3.83G [00:00<00:49, 77.0MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:   4%|▏     | 195M/5.00G [00:01<00:16, 287MB/s]\u001b[A\n",
      "model-00003-of-00003.safetensors:   5%|▎     | 181M/3.83G [00:01<00:13, 271MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:   0%|    | 778k/4.95G [00:01<1:53:24, 727kB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:   5%|▎     | 274M/5.00G [00:01<00:12, 371MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:   3%|▏     | 135M/4.95G [00:01<00:43, 111MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:   8%|▍     | 413M/5.00G [00:01<00:15, 304MB/s]\u001b[A\n",
      "model-00003-of-00003.safetensors:   7%|▍     | 255M/3.83G [00:01<00:20, 176MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  21%|▊   | 1.07G/5.00G [00:01<00:03, 1.11GB/s]\u001b[A\n",
      "model-00003-of-00003.safetensors:  21%|█▎    | 814M/3.83G [00:01<00:03, 755MB/s]\u001b[A\n",
      "model-00003-of-00003.safetensors:  26%|█▎   | 1.01G/3.83G [00:02<00:03, 870MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  14%|▊     | 671M/4.95G [00:02<00:09, 463MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  26%|█▎   | 1.28G/4.95G [00:02<00:04, 915MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  30%|█▍   | 1.48G/4.95G [00:02<00:04, 782MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  33%|█▋   | 1.61G/4.95G [00:02<00:04, 753MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  26%|█▎   | 1.31G/5.00G [00:03<00:07, 481MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  35%|█▊   | 1.75G/4.95G [00:02<00:04, 771MB/s]\u001b[A\n",
      "model-00003-of-00003.safetensors:  32%|█▌   | 1.22G/3.83G [00:03<00:06, 429MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  38%|█▉   | 1.88G/4.95G [00:03<00:03, 805MB/s]\u001b[A\n",
      "model-00003-of-00003.safetensors:  35%|█▊   | 1.35G/3.83G [00:03<00:05, 486MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  30%|█▌   | 1.51G/5.00G [00:03<00:06, 540MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  41%|██   | 2.02G/4.95G [00:03<00:03, 819MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  34%|█▋   | 1.71G/5.00G [00:03<00:05, 647MB/s]\u001b[A\n",
      "model-00003-of-00003.safetensors:  39%|█▉   | 1.49G/3.83G [00:03<00:04, 501MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  43%|██▏  | 2.15G/4.95G [00:03<00:03, 799MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  37%|█▊   | 1.85G/5.00G [00:03<00:04, 719MB/s]\u001b[A\n",
      "model-00003-of-00003.safetensors:  44%|██▏  | 1.69G/3.83G [00:03<00:03, 641MB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  48%|██▍  | 2.35G/4.95G [00:03<00:02, 946MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  41%|██   | 2.05G/5.00G [00:03<00:03, 846MB/s]\u001b[A\n",
      "model-00003-of-00003.safetensors:  48%|██▍  | 1.82G/3.83G [00:03<00:02, 703MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  45%|█▊  | 2.25G/5.00G [00:03<00:02, 1.02GB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  52%|██  | 2.55G/4.95G [00:03<00:02, 1.07GB/s]\u001b[A\n",
      "model-00003-of-00003.safetensors:  53%|██▋  | 2.02G/3.83G [00:03<00:02, 863MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  49%|█▉  | 2.45G/5.00G [00:03<00:02, 1.13GB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  56%|██▏ | 2.75G/4.95G [00:03<00:01, 1.18GB/s]\u001b[A\n",
      "model-00003-of-00003.safetensors:  56%|██▊  | 2.16G/3.83G [00:03<00:01, 944MB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  53%|██  | 2.65G/5.00G [00:04<00:01, 1.24GB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  58%|██▎ | 2.89G/4.95G [00:04<00:01, 1.16GB/s]\u001b[A\n",
      "model-00003-of-00003.safetensors:  62%|██▍ | 2.36G/3.83G [00:04<00:01, 1.07GB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  57%|██▎ | 2.85G/5.00G [00:04<00:01, 1.33GB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  62%|██▍ | 3.09G/4.95G [00:04<00:01, 1.29GB/s]\u001b[A\n",
      "model-00003-of-00003.safetensors:  67%|██▋ | 2.56G/3.83G [00:04<00:01, 1.18GB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  61%|██▍ | 3.05G/5.00G [00:04<00:01, 1.48GB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  66%|██▋ | 3.29G/4.95G [00:04<00:01, 1.30GB/s]\u001b[A\n",
      "model-00003-of-00003.safetensors:  72%|██▉ | 2.76G/3.83G [00:04<00:00, 1.29GB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  65%|██▌ | 3.25G/5.00G [00:04<00:01, 1.51GB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  71%|██▊ | 3.49G/4.95G [00:04<00:01, 1.36GB/s]\u001b[A\n",
      "model-00003-of-00003.safetensors:  77%|███ | 2.96G/3.83G [00:04<00:00, 1.39GB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  69%|██▊ | 3.46G/5.00G [00:04<00:00, 1.57GB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  75%|██▉ | 3.69G/4.95G [00:04<00:00, 1.46GB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  73%|██▉ | 3.66G/5.00G [00:04<00:00, 1.64GB/s]\u001b[A\n",
      "model-00003-of-00003.safetensors:  82%|███▎| 3.16G/3.83G [00:04<00:00, 1.38GB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  78%|███▏| 3.88G/4.95G [00:04<00:00, 1.50GB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  77%|███ | 3.86G/5.00G [00:04<00:00, 1.65GB/s]\u001b[A\n",
      "model-00003-of-00003.safetensors:  88%|███▌| 3.36G/3.83G [00:04<00:00, 1.47GB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  82%|███▎| 4.08G/4.95G [00:04<00:00, 1.56GB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  83%|███▎| 4.13G/5.00G [00:04<00:00, 1.82GB/s]\u001b[A\n",
      "model-00003-of-00003.safetensors:  93%|███▋| 3.56G/3.83G [00:04<00:00, 1.53GB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  86%|███▍| 4.28G/4.95G [00:04<00:00, 1.61GB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  87%|███▍| 4.33G/5.00G [00:05<00:00, 1.79GB/s]\u001b[A\n",
      "model-00003-of-00003.safetensors: 100%|█████| 3.83G/3.83G [00:05<00:00, 760MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00003.safetensors:  91%|███▌| 4.48G/4.95G [00:04<00:00, 1.64GB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  91%|███▌| 4.53G/5.00G [00:05<00:00, 1.77GB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors:  95%|███▊| 4.68G/4.95G [00:05<00:00, 1.67GB/s]\u001b[A\n",
      "model-00001-of-00003.safetensors:  95%|███▊| 4.73G/5.00G [00:05<00:00, 1.76GB/s]\u001b[A\n",
      "model-00002-of-00003.safetensors: 100%|█████| 4.95G/4.95G [00:05<00:00, 940MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00003.safetensors: 100%|█████| 5.00G/5.00G [00:05<00:00, 930MB/s]\u001b[A\n",
      "Fetching 3 files: 100%|███████████████████████████| 3/3 [00:05<00:00,  1.81s/it]\n",
      "Fetching 3 files: 100%|███████████████████████████| 3/3 [00:05<00:00,  1.82s/it]\n",
      "Fetching 3 files: 100%|███████████████████████████| 3/3 [00:05<00:00,  1.80s/it]\n",
      "Fetching 3 files: 100%|███████████████████████████| 3/3 [00:05<00:00,  1.82s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:17<00:00,  5.84s/it]\n",
      "generation_config.json: 100%|███████████████████| 111/111 [00:00<00:00, 935kB/s]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:18<00:00,  6.17s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:18<00:00,  6.17s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:18<00:00,  6.17s/it]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "trainable params: 159,907,840 || all params: 7,048,003,584 || trainable%: 2.268838800862903\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "[rank0]:[W Utils.hpp:106] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)\n",
      "[rank1]:[W Utils.hpp:106] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)\n",
      "[rank2]:[W Utils.hpp:106] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)\n",
      "[rank3]:[W Utils.hpp:106] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "\n",
      "  | Name  | Type                 | Params\n",
      "-----------------------------------------------\n",
      "0 | model | PeftModelForCausalLM | 3.8 B \n",
      "-----------------------------------------------\n",
      "159 M     Trainable params\n",
      "3.7 B     Non-trainable params\n",
      "3.8 B     Total params\n",
      "15,240.004Total estimated model params size (MB)\n",
      "Epoch 0: |         | 1833/? [47:16<00:00,  0.65it/s, v_num=10, train_loss=0.491]/opt/conda/envs/pytorch/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "Training complete. Saving adapter to temporary local storage...\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/Harindhar/train_uspto.py\", line 199, in <module>\n",
      "    pl_model.model.save_pretrained(\"./temp_adapter_uspto\")\n",
      "  File \"/opt/conda/envs/pytorch/lib/python3.10/site-packages/peft/peft_model.py\", line 218, in save_pretrained\n",
      "    output_state_dict = get_peft_model_state_dict(\n",
      "  File \"/opt/conda/envs/pytorch/lib/python3.10/site-packages/peft/utils/save_and_load.py\", line 71, in get_peft_model_state_dict\n",
      "    state_dict = model.state_dict()\n",
      "  File \"/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1895, in state_dict\n",
      "    module.state_dict(destination=destination, prefix=prefix + name + '.', keep_vars=keep_vars)\n",
      "  File \"/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1895, in state_dict\n",
      "    module.state_dict(destination=destination, prefix=prefix + name + '.', keep_vars=keep_vars)\n",
      "  File \"/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1895, in state_dict\n",
      "    module.state_dict(destination=destination, prefix=prefix + name + '.', keep_vars=keep_vars)\n",
      "  [Previous line repeated 5 more times]\n",
      "  File \"/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1892, in state_dict\n",
      "    self._save_to_state_dict(destination, prefix, keep_vars)\n",
      "  File \"/opt/conda/envs/pytorch/lib/python3.10/site-packages/bitsandbytes/nn/modules.py\", line 443, in _save_to_state_dict\n",
      "    for k, v in self.weight.quant_state.as_dict(packed=True).items():\n",
      "  File \"/opt/conda/envs/pytorch/lib/python3.10/site-packages/bitsandbytes/functional.py\", line 757, in as_dict\n",
      "    \"nested_offset\": self.offset.item(),\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train_uspto.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1513ca91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
